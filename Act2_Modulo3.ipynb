{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e500e23",
   "metadata": {},
   "source": [
    "### Equipo de Angie y las Rss \n",
    "\n",
    "#### Jose Pablo Cobos Austria   A01274631\n",
    "#### Rodrigo Marquina Magaña  A01706219\n",
    "#### Angélica Medina Ramírez    A01274616\n",
    "#### Raúl Sebastián Uribe Sosa  A01275964\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b2309",
   "metadata": {},
   "source": [
    "\n",
    "## ASL dataset\n",
    "\n",
    "For this first notebook, we will use the ASL dataset from Kaggle in https://www.kaggle.com/datasets/grassknoted/asl-alphabet, that we already know. This dataset is more complex than MNIST, but still allows us to implement a FC network to process it. Later on, we will use more complex datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183db241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#PyTorch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Solamente para usuarios de Jupyter Themes\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3896ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa938e",
   "metadata": {},
   "source": [
    "### Always a good idea to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2d1df",
   "metadata": {},
   "source": [
    "### Get training label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7edd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    assert x.shape[0] == y.shape[0], 'Number of samples x!= number samples y'\n",
    "    total_samples = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(x.shape[0])\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        #return x_val, y_val, x_test, y_test\n",
    "        return x[:total_samples//2, :], y[:total_samples//2], x[total_samples//2:, :], y[total_samples//2:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17874be",
   "metadata": {},
   "source": [
    "### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eef77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9216b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(len(y_val))\n",
    "# print(rnd_idx)\n",
    "# print(y_val[rnd_idx])\n",
    "print(f'La imagen muestreada representa un: {alphabet[y_val[rnd_idx]]}')\n",
    "plot_number(x_val[rnd_idx].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cfc56",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c833b",
   "metadata": {},
   "source": [
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae3ef9",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780beecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(create_minibatches(128,x_train, y_train)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c2954",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size, neurons):\n",
    "    \n",
    "    '''\n",
    "    input_size -> elementos de entrada, 784\n",
    "    neurons -> list [200, 24] con cantidad de neuronas en cada capa\n",
    "    '''\n",
    "    \n",
    "    W1 = np.random.randn(neurons[0], input_size) / np.sqrt(input_size/2)\n",
    "    b1 = np.zeros((neurons[0], 1))\n",
    "    \n",
    "    W2 = np.random.randn(neurons[1], neurons[0]) / np.sqrt(neurons[0]/2)\n",
    "    b2 = np.zeros((neurons[1], 1))\n",
    "    \n",
    "    return {'W1': W1, 'b1':b1, 'W2':W2, 'b2':b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6083b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = init_parameters(28*28, [200, 24])\n",
    "print(parameters['W1'].shape)\n",
    "print(parameters['W2'].shape)\n",
    "print(parameters['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aaaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(x, parameters, activation_fcn):\n",
    "    '''\n",
    "    x tiene la forma (#pixeles, num samples)\n",
    "    '''\n",
    "    z1 = parameters['W1'] @ x + parameters['b1']\n",
    "    a1 = activation_fcn(z1) # devuel fcn. de activa.\n",
    "    z2 = parameters['W2'] @ a1 + parameters['b2']\n",
    "    \n",
    "    return z2, z1, a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a10f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2,z1, a1 = scores(x_train[:64].T, parameters, relu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:64].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_scores = np.exp(x)\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=0)\n",
    "    probs = exp_scores/(sum_exp_scores)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e22d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_entropy(scores, y, batch_size=64):\n",
    "    probs = softmax(scores)\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    \n",
    "    return probs, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(probs, x, y, z1, a1, scores, parameters, batch_size=64):\n",
    "    grads = {}\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 # y-hat - y\n",
    "    dz2 = probs.copy()\n",
    "    \n",
    "    dW2 = dz2 @ a1.T / batch_size\n",
    "    db2 = np.sum(dz2, axis =1, keepdims=True) / batch_size\n",
    "    da1 = parameters['W2'].T @ dz2\n",
    "    \n",
    "    dz1 = da1.copy()\n",
    "    dz1[z1 <= 0 ] =0\n",
    "    \n",
    "    dW1 = dz1 @ x \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) \n",
    "    \n",
    "    assert parameters['W1'].shape == dW1.shape, 'W1 no igual forma'\n",
    "    assert parameters['W2'].shape == dW2.shape, 'W2 no igual forma'\n",
    "    assert parameters['b1'].shape == db1.shape, 'b1 no igual forma'\n",
    "    assert parameters['b2'].shape == db2.shape, 'b2 no igual forma'\n",
    "    \n",
    "    grads = {'w1':dW1,  'b1':db1, 'W2':dW2, 'b2':db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, cost = x_entropy(scores2, y_train[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ac650",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward(y_hat, x_train[:64], y_train[:64],z1, a1, scores2, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_data, y_data, mb_size=64):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x_data, y_data)):\n",
    "        scores2, z1, a1 = scores(x.T, parameters, relu)\n",
    "        y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "        correct += np.sum(np.argmax(y_hat, axis=0) == y.squeeze())\n",
    "        total += y_hat.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, parameters, mb_size=64, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores2, z1, a1 = scores(x.T, parameters=parameters, activation_fcn=relu)\n",
    "            y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "            train_correct += np.sum(np.argmax(y_hat.copy(), axis=0) == y.squeeze())\n",
    "            train_total += y_hat.shape[1]            \n",
    "            grads = backward(y_hat, x, y, z1, a1, scores2, parameters, batch_size=len(x))\n",
    "            \n",
    "            parameters['W1'] = parameters['W1'] - learning_rate*grads['w1']\n",
    "            parameters['b1'] = parameters['b1'] - learning_rate*grads['b1']\n",
    "            parameters['b2'] = parameters['b2'] - learning_rate*grads['b2']\n",
    "            parameters['W2'] = parameters['W2'] - learning_rate*grads['W2']\n",
    "            \n",
    "        train_acc = float(train_correct)/train_total\n",
    "        if epoch % 20 == 0:\n",
    "            print(f' epoch: {epoch}, train cost is: {cost:.6f}, train acc:{train_acc:.4f},  val acc: {accuracy(x_val, y_val, mb_size):.4f}')\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 256\n",
    "learning_rate = 0.00001\n",
    "epochs = 200\n",
    "parameters = init_parameters(28*28, [512, 24])\n",
    "trained_parameters = train(epochs=epochs, parameters=parameters, mb_size=mb_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(x_train, y_train, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(x_test, y_test, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    scores2, _, _ = scores(x, parameters, relu)\n",
    "    return np.argmax(scores2)\n",
    "\n",
    "x_test[0].reshape(-1, 1).shape\n",
    "\n",
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a64f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
